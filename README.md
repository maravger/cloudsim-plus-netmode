# netmode-cloudsim
A computational offloading simulation scenario using CloudSim Plus tools. 

The whole setting is supposed to resemble a Smart Museum. We assume one application of the Interactive Exhibit type, denoted as App1 and one of the Sensor Monitoring type, denoted as App2, co-hosted in each site. This means that VMs of both application types are able to run simultaneously in the edge servers, receiving offloading requests from their counterparts in the visitors' mobile devices and the IoT sensors, respectively. These VMs can be of various “flavors”, i.e. VM sizes/types. We assume that both apps are based on image recognition processes, thus their acceptable response time (QoS) is set at 3sec, which lies within the margins of a typical image recognition service time. However, App1 requests require considerably heavier computations to achieve this response time than the ones of App2, a fact that limits the Maximum App1 Requests served per Slot to a third of those served by the App2 equally sized VMs. The system slot is arbitrarily set at 30sec and the experiments last for a period of 1 hour, or 120 system slots. However, you change that by setting the respective variable.

Predicting the users' positions in the next system slot via recognizing their moving patterns is the first step of optimizing the allocation of the edge resources in each site. This provides an estimation on the projected workload. Having available the users' projected positions for the next system slot, a conversion into predicted incoming workload in terms of requests per slot, takes place. This embodies the input of the optimization algorithm. Finally, it should be emphasized that the incoming workload for static App2 is estimated likewise. Sensors are considered as non-moving visitors.

With the predicted incoming workload available, the next step is to proactively optimize resource allocation, in terms of edge servers and the VMs placed in them, for the next system slot. The optimizer selects the appropriate topology in terms of number of active edge servers and their allocated cores, in order to meet the demands.

Excess workload requests, above the computational resources of a site, are distributed in neighboring (or even farther apart) sites. The excess workload is handled in such a way that it does not allow sites to become operational for a number of requests lower than a threshold of their total capacity, which will ensure eventually better energy efficiency, as explained in previous subsections. To achieve this, we employ the theory of Markov Random Fields (MRFs), which closes a single system loop.
